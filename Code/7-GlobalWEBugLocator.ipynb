{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>GlobalWEBugLocator</h1></center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this method we perform the localization directly and indirectly using the the TFIDF similarity score of bug reports to source codes in each project individually. Note that TF.IDF scores are calculated using the local data. That means that for each term we calculate the term frequency and inverse document frequency of that term using only the bug reports and source codes of that project. \n",
    "- Note that both TF.IDF and Doc2Vec scores are calculated using the __global data__. That means that for each term we calculate the term frequency and inverse document frequency of that term using all bug reports and source codes of all projects. \n",
    "- Refer to the third row of the following table (Method7 - Global Doc2Vec + TFIDF) to better understand the details of this method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Methods.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim import similarities\n",
    "from gensim import models\n",
    "\n",
    "import traceback\n",
    "import logging\n",
    "\n",
    "import operator\n",
    "import warnings\n",
    "import glob\n",
    "import math \n",
    "from scipy import spatial\n",
    "import scipy.spatial.distance\n",
    "import multiprocessing\n",
    "from tqdm import tqdm_notebook\n",
    "from time import gmtime, strftime\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Evaluators</h1></center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_helper(ranked_files,fixes):\n",
    "    \"\"\"\n",
    "    @Receives: list of ranked files(which is predicted by algorithm) and the ground truth(fixes)\n",
    "    @Process: This is a function aimed to help evaluate, and calculates the AP and first_pos \n",
    "    @Returns: A dictionary containing the AP(average precision) and first_pos (first retrieved fix file)\n",
    "    \"\"\"\n",
    "    found=0\n",
    "    first_pos=-1\n",
    "    average_precision=0\n",
    "    for i,predictionFix in enumerate(ranked_files):\n",
    "        for actualFix in fixes:\n",
    "            if actualFix.split('.')[-2] == predictionFix:\n",
    "                if first_pos==-1:\n",
    "                    first_pos=i+1\n",
    "                found+=1\n",
    "                average_precision+=found/(i+1)        \n",
    "\n",
    "    AP=average_precision/found if found>0 else 0\n",
    "    return {\"AP\":AP,\"first_pos\":first_pos}\n",
    "\n",
    "\n",
    "def evaluate(all_bugs_df,source_codes_df):\n",
    "    \"\"\"\n",
    "    @Receives: The main dataframe\n",
    "    @Process: Evaluates the predicted files for each bugreport in all_bugs_df\n",
    "    @Returns: MAP and MRR calculated from eligible bugreports(the ones with\n",
    "    at least one fix file in this version of code) in the dataframe and number of eligible bug reports.\n",
    "    \"\"\"\n",
    "    all_results=[]\n",
    "    top_founds=[]\n",
    "    average_precisions=[]\n",
    "    for i,br in all_bugs_df.iterrows():\n",
    "        if not source_codes_df.loc[source_codes_df.filename.apply(lambda filename: any(fix in filename for fix in br['fix']))].empty:\n",
    "            predicted_files=br['total_score'].keys()\n",
    "            result=evaluate_helper(predicted_files,br['fix'])\n",
    "            top_founds.append(result['first_pos'])\n",
    "            average_precisions.append(result['AP'])\n",
    "            all_results.append(result)\n",
    "        else:\n",
    "            top_founds.append(-1)\n",
    "            average_precisions.append(0.0)\n",
    "    all_bugs_df[\"top_found\"]=top_founds\n",
    "    all_bugs_df[\"average_precision\"]=average_precisions\n",
    "    \n",
    "    #Calculating the MAP and MRR\n",
    "    MAP,MRR=(0,0)\n",
    "    if len(all_results)>0:\n",
    "        for result in all_results:\n",
    "            MAP+=result['AP']\n",
    "            MRR+=1/result['first_pos'] if result['first_pos']>0 else 0\n",
    "        MAP/=len(all_results)\n",
    "        MRR/=len(all_results)\n",
    "        print(\"eligible_br_count: \",len(all_results))\n",
    "    return (MAP,MRR,len(all_results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>TFIDF</h1></center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNormValue(x,maximum,minimum):\n",
    "    return 6*((x - minimum)/(maximum - minimum))\n",
    "\n",
    "def getLenScore(length):\n",
    "    return (math.exp(length) / (1 + math.exp(length)))\n",
    "\n",
    "def calulateLengthScore(source_codes_df):\n",
    "    \"\"\"\n",
    "    Receives: a list of sizes of codes and the index\n",
    "    Process: calculate a boost score for the specified index based on length of that code\n",
    "    Returns: length boosting score \n",
    "    \"\"\"\n",
    "    average_size=source_codes_df['size'].mean()\n",
    "    standard_deviation=source_codes_df['size'].std() \n",
    "    low=average_size-3*standard_deviation\n",
    "    high= average_size+3*standard_deviation\n",
    "    minimum=int(low) if low>0 else 0\n",
    "        \n",
    "    len_scores=[]\n",
    "    for i,eachLen in source_codes_df['size'].items():\n",
    "        score=0\n",
    "        nor=getNormValue(eachLen,high,minimum)\n",
    "        if eachLen!=0:\n",
    "            if eachLen>=low and eachLen<=high:\n",
    "                score=getLenScore(nor)\n",
    "            elif eachLen<low:\n",
    "                score=0.5\n",
    "            elif eachLen>high:\n",
    "                score = 1.0\n",
    "        len_scores.append(score)\n",
    "    source_codes_df['lengthScore']=len_scores\n",
    "\n",
    "    return source_codes_df\n",
    "    \n",
    "def inverse_doc_freq(idf,D):\n",
    "    return math.log(D/idf)\n",
    "\n",
    "def term_freq(tf_list):\n",
    "    return [(math.log(tf+1)) for tf in tf_list]\n",
    "\n",
    "def np_normalizer(arr):\n",
    "    \"\"\"\n",
    "    @Receives: a list of numbers\n",
    "    @Process: normalizes all the values and map them to range of [0,1]\n",
    "    @Returns: list of normalized numbers\n",
    "    \"\"\"\n",
    "    if len(arr)>0:\n",
    "        maximum=np.amax(arr)\n",
    "        minimum=np.amin(arr)\n",
    "        if maximum!=minimum:\n",
    "            return (arr-minimum)/(maximum-minimum)\n",
    "    return arr\n",
    "\n",
    "def normalizer(Dict):\n",
    "    \"\"\"\n",
    "    @Receives: a list of numbers\n",
    "    @Process: normalizes all the values and map them to range of [0,1]\n",
    "    @Returns: list of normalized numbers\n",
    "    \"\"\"\n",
    "    if len(Dict)>0:\n",
    "        maximum=max(Dict.items(), key=operator.itemgetter(1))[1]\n",
    "        minimum=min(Dict.items(), key=operator.itemgetter(1))[1]\n",
    "        for key,value in Dict.items():\n",
    "            if maximum!=minimum:\n",
    "                Dict[key]=(value-minimum)/(maximum-minimum)\n",
    "            else:\n",
    "                Dict[key]=1.0\n",
    "            \n",
    "    return Dict\n",
    "    \n",
    "\n",
    "def TFIDF_transform(all_bugs_df,source_codes_df):\n",
    "    \n",
    "    print(\"\\tTransforming to TF.IDF ...\")\n",
    "    dictionary = gensim.corpora.Dictionary(list(source_codes_df['code']))\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in list(source_codes_df['code'])]\n",
    "    tfidf_weights = models.TfidfModel(corpus,wlocal=term_freq,wglobal=inverse_doc_freq,normalize=False)\n",
    "    source_codes_df['tfidf_vector']=tfidf_weights[corpus]\n",
    "    all_bugs_df['tfidf_vector']=all_bugs_df.text.apply(lambda x: tfidf_weights[dictionary.doc2bow(x)])\n",
    "    return (all_bugs_df,source_codes_df,len(dictionary))\n",
    "\n",
    "def cos_matrix_multiplication(matrix, vector):\n",
    "    \"\"\"\n",
    "    Calculating pairwise cosine distance using matrix vector multiplication.\n",
    "    \"\"\"\n",
    "    dotted = matrix.dot(vector)\n",
    "    matrix_norms = np.linalg.norm(matrix, axis=1)\n",
    "    vector_norm = np.linalg.norm(vector)\n",
    "    matrix_vector_norms = np.multiply(matrix_norms, vector_norm)\n",
    "    neighbors = np.divide(dotted, matrix_vector_norms)\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> Genral Global Doc2Vec Model </h1></center> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_BRs(dataPath):\n",
    "    print('\\tLoading all bug reports ... ')\n",
    "    all_bugs_df=pd.DataFrame([])\n",
    "    all_groups=[folder for folder in listdir(dataPath)]\n",
    "    for group in tqdm_notebook(all_groups):\n",
    "        all_projects= [folder for folder in listdir(os.path.join(dataPath,group))]\n",
    "        for project in all_projects:\n",
    "            data_path=os.path.join(dataPath,group,project,\"bugrepo\",\"repository.xml\")\n",
    "            all_bugs_df=all_bugs_df.append(loadBugs2df(data_path,project))\n",
    "            print(len(all_bugs_df))\n",
    "    return all_bugs_df\n",
    "\n",
    "def load_all_SCs(dataPath):\n",
    "    print('\\tLoading all source codes ... ')\n",
    "    source_codes_df=pd.DataFrame([])\n",
    "    all_groups=[folder for folder in listdir(dataPath)]\n",
    "    for group in tqdm_notebook(all_groups):\n",
    "        all_projects= [folder for folder in listdir(os.path.join(dataPath,group))]\n",
    "        for project in all_projects:\n",
    "            source_path=os.path.join(dataPath,group,project,\"gitrepo\")\n",
    "            source_codes_df=source_codes_df.append(loadSourceFiles2df(source_path,group,project))\n",
    "    return source_codes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_Doc2Vec_models(vec_size,alpha,window_size,all_bugs_df,source_codes_df):\n",
    "    \"\"\"\n",
    "    Process: 1- Loads all the bug reports from all the group/projects in Data directory\n",
    "             2- Makes a Doc2Vec model and trains it based on all the bugreports\n",
    "    Returns: Trained model\n",
    "    \"\"\"\n",
    "    print(\"\\n\\t Now building the Combined Doc2Vec model ... \")\n",
    "    dmm_model_path=os.path.join(os.getcwd(),'Models','combined_doc2vec_model_dmm')\n",
    "    dbow_model_path=os.path.join(os.getcwd(),'Models','combined_doc2vec_model_dbow')\n",
    "    fname_dmm = get_tmpfile(dmm_model_path)\n",
    "    fname_dbow = get_tmpfile(dbow_model_path)\n",
    "    if os.path.isfile(dmm_model_path) and os.path.isfile(dbow_model_path):\n",
    "        revectorize=False\n",
    "        model_dmm = Doc2Vec.load(fname_dmm)\n",
    "        model_dbow = Doc2Vec.load(fname_dbow)\n",
    "        print(\"*** Combined Doc2Vec Model is Loaded. ***\")            \n",
    "    else:\n",
    "        revectorize=True\n",
    "        documents = [TaggedDocument(all_bugs_df.iloc[i].text, [i]) for i in range(len(all_bugs_df))]\n",
    "        documents = documents + [TaggedDocument(source_codes_df.iloc[i].code, [len(all_bugs_df)+i]) for i in range(len(source_codes_df))]\n",
    "\n",
    "        model_dmm = Doc2Vec(vector_size=vec_size, window=window_size, min_count=2,\n",
    "                        workers=multiprocessing.cpu_count(),\n",
    "                        alpha=alpha, min_alpha=alpha/2,dm=1)\n",
    "        model_dmm.build_vocab(documents)\n",
    "        model_dmm.train(documents,total_examples=model_dmm.corpus_count,epochs=20)\n",
    "        model_dmm.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "        model_dmm.save(fname_dmm)\n",
    "        \n",
    "        model_dbow = Doc2Vec(dm=0, vector_size=vec_size, negative=5,\n",
    "                             hs=0,min_count=2, sample = 0, workers=multiprocessing.cpu_count(),\n",
    "                             alpha=alpha, min_alpha=alpha/3)\n",
    "        model_dbow.build_vocab(documents)\n",
    "        model_dbow.train(documents,total_examples=model_dbow.corpus_count,epochs=20)\n",
    "        model_dbow.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "        model_dbow.save(fname_dbow)\n",
    "        print(\"*** Combined Doc2Vec Model is Trained. ***\")\n",
    "    concatinated_model = ConcatenatedDoc2Vec([model_dbow, model_dmm])\n",
    "    print(\">> Size of Vocabulary is: {}\".format(len(model_dmm.wv.vocab)))\n",
    "    print(\">> Number of whole Documents: {}\".format(model_dmm.corpus_count))\n",
    "    \n",
    "    return (concatinated_model,revectorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize(sourceCodeScores,bugReportScores):\n",
    "    sourceCodeScores=normalizer(sourceCodeScores)\n",
    "    bugReportScores=normalizer(bugReportScores)\n",
    "    for file in bugReportScores.keys():\n",
    "        if file in sourceCodeScores.keys():\n",
    "            sourceCodeScores[file]=sourceCodeScores[file]*0.8+bugReportScores[file]*0.2\n",
    "    return sourceCodeScores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<center><h1>Main BugLocalization class</h1></center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BugLocalizer:\n",
    "    \n",
    "    TFIDF_transformed=False\n",
    "    dictionary_length=0\n",
    "    all_projects_source_codes=pd.DataFrame([])\n",
    "    all_projects_bugreports=pd.DataFrame([])\n",
    "    dataFolder=\"\"\n",
    "    \n",
    "    def __init__(self,group,project,result_path,dataPath):\n",
    "        self.project=project\n",
    "        self.resultPath=result_path\n",
    "            \n",
    "    def execute(self):\n",
    "        print(\"\\t ****** Localizing Bugs for project: {} ******\".format(self.project))\n",
    "        vectorize=self.loadEverything()\n",
    "        revectorize=False\n",
    "        \n",
    "        if not BugLocalizer.TFIDF_transformed:\n",
    "            (self.all_projects_bugreports,BugLocalizer.all_projects_source_codes,BugLocalizer.dictionary_length)=TFIDF_transform(all_bugs_df=BugLocalizer.all_projects_bugreports,\n",
    "                                                                                                     source_codes_df=BugLocalizer.all_projects_source_codes)                                       \n",
    "            BugLocalizer.TFIDF_transformed=True\n",
    "\n",
    "        self.loadBugCurpus()\n",
    "        self.loadSourceFiles()\n",
    "        self.localize()\n",
    "        self.evaluate()\n",
    "        self.to_csv()\n",
    "        self.write_result()\n",
    "        \n",
    "    def loadEverything():\n",
    "        if BugLocalizer.all_projects_bugreports.empty:\n",
    "            bugReportFile=os.path.join(BugLocalizer.dataFolder,'allBugReports.pickle')\n",
    "            if not os.path.isfile(bugReportFile):\n",
    "                print(\"The bug reports file (allBugReports.pickle) does not exist. please run the step0 first\")\n",
    "            else: \n",
    "                BugLocalizer.all_projects_bugreports=pd.read_pickle(bugReportFile)\n",
    "                print(\"*** All Bug Reports are Loaded. ***\")\n",
    "\n",
    "        if BugLocalizer.all_projects_source_codes.empty:\n",
    "            sourceCodeFile=os.path.join(BugLocalizer.dataFolder,'allSourceCodes.pickle')\n",
    "            if not os.path.isfile(sourceCodeFile):\n",
    "                print(\"The source codes file (allSourceCodes.pickle) does not exist. please run the step0 first\")\n",
    "            else:\n",
    "                BugLocalizer.all_projects_source_codes=pd.read_pickle(sourceCodeFile)\n",
    "                print(\"*** All Source Codes are Loaded. ***\")\n",
    "    \n",
    "    def loadBugCurpus(self):\n",
    "        self.all_bugs_df=BugLocalizer.all_projects_bugreports.loc[BugLocalizer.all_projects_bugreports['project']==self.project,:]\n",
    "    \n",
    "    def loadSourceFiles(self):\n",
    "        self.source_codes_df=BugLocalizer.all_projects_source_codes.loc[BugLocalizer.all_projects_source_codes['project']==self.project,:]\n",
    "    \n",
    "    def vectorizeBugreports(self):\n",
    "        BugLocalizer.all_projects_bugreports['doc2vec_vector']=np.array(BugLocalizer.all_projects_bugreports.text.apply(BugLocalizer.combined_Doc2vec.infer_vector))\n",
    "        \n",
    "    def vectorizeSourceCodes(self):\n",
    "        BugLocalizer.all_projects_source_codes['doc2vec_vector']=np.array(BugLocalizer.all_projects_source_codes.code.apply(BugLocalizer.combined_Doc2vec.infer_vector))\n",
    "     \n",
    "\n",
    "    def localize(self):\n",
    "        \n",
    "        print(\"Localizing Now ...\")\n",
    "        self.source_codes_df=calulateLengthScore(self.source_codes_df)\n",
    "        scores=[]\n",
    "        direct_tfidf_index = similarities.SparseMatrixSimilarity(list(self.source_codes_df.tfidf_vector),num_features=BugLocalizer.dictionary_length)\n",
    "        indirect_WE_index=np.array(list(self.all_bugs_df.doc2vec_vector))\n",
    "        indirectScores=[]\n",
    "        BRRanks=[]\n",
    "        for i, br in tqdm_notebook(self.all_bugs_df.iterrows()):\n",
    "            \n",
    "            try:\n",
    "                direct_tfidf_similarities=direct_tfidf_index[br.tfidf_vector]\n",
    "                direct_tfidf_similarities=np_normalizer(direct_tfidf_similarities)\n",
    "                sourceCodeScores={self.source_codes_df.iloc[j].filename.split('.')[-2]: (direct_tfidf_similarities[j])*self.source_codes_df.iloc[j].lengthScore \n",
    "                                                  for j in range(len(self.source_codes_df))\n",
    "                                                  if len(self.source_codes_df.iloc[j].filename.split('.'))>1}                                  \n",
    "\n",
    "                indirect_WE_similarities=cos_matrix_multiplication(indirect_WE_index, br.doc2vec_vector)\n",
    "                bugReportScores=dict({})\n",
    "                for j,(idx,other_br) in enumerate(self.all_bugs_df.iterrows()):\n",
    "                    for fixFile in other_br.fix:\n",
    "                        if idx != i:\n",
    "                            if fixFile.split('.')[-2] in bugReportScores.keys():\n",
    "                                if indirect_WE_similarities[j]>=bugReportScores[fixFile.split('.')[-2]]:\n",
    "                                    bugReportScores[fixFile.split('.')[-2]]=indirect_WE_similarities[j]\n",
    "                            else:\n",
    "                                bugReportScores[fixFile.split('.')[-2]]=indirect_WE_similarities[j]\n",
    "                indirectScores.append(bugReportScores)\n",
    "                BRRanks.append({idx:indirect_WE_similarities[j] for j,(idx,other_br) in enumerate(self.all_bugs_df.iterrows())})\n",
    "                ranking=synthesize(sourceCodeScores,bugReportScores)\n",
    "                scores.append({file:score for file,score in sorted(ranking.items(),key=lambda tup: tup[1],reverse=True)})\n",
    "            except Exception as e:\n",
    "                logging.error(traceback.format_exc())\n",
    "                scores.append({})\n",
    "                \n",
    "        self.all_bugs_df['Indirect_scores']=indirectScores\n",
    "        self.all_bugs_df['BR_scores']=BRRanks                \n",
    "        self.all_bugs_df['total_score']=scores\n",
    "\n",
    "        \n",
    "    def evaluate(self):\n",
    "        self.result=evaluate(self.all_bugs_df,self.source_codes_df)\n",
    "        print(\"Result/\"+self.project+\":\\n\\t\",'*'*4,\" MAP: \",self.result[0],'*'*4,'\\n\\t','*'*4,\" MRR: \",self.result[1],'*'*4,\"\\n\",\"-\"*100)\n",
    "\n",
    "    def to_csv(self):\n",
    "        BugReports_path=os.path.join(self.resultPath,'BugReports') \n",
    "        SourceFiles_path=os.path.join(self.resultPath,'SourceFiles')\n",
    "        if not os.path.exists(BugReports_path):\n",
    "            os.makedirs(BugReports_path)\n",
    "        if not os.path.exists(SourceFiles_path):\n",
    "            os.makedirs(SourceFiles_path)\n",
    "        result_Bug_file=os.path.join(BugReports_path,self.project+\"_BugReports.csv\")\n",
    "        result_source_file=os.path.join(SourceFiles_path,self.project+\"_SourceFiles.csv\")\n",
    "        self.all_bugs_df.to_csv(result_Bug_file)\n",
    "        if len(self.all_bugs_df)<300:        \n",
    "            self.source_codes_df.to_csv(result_source_file)\n",
    "        \n",
    "    def write_result(self):\n",
    "        group_result=open(os.path.join(self.resultPath,\"results_{}.csv\".format(self.project)),'w')\n",
    "        group_result.write(\"project , MAP , MRR , #ofBugReports\\n\")\n",
    "        group_result.write(project+','+str(self.result[0])+','+str(self.result[1])+','+str(self.result[2])+\"\\n\")\n",
    "        group_result.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t ****** Localizing Bugs for group: Spring , project: DATAREST ******\n",
      "Localizing Now ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a1f9d50d5cb4778bf59d9b5bbaf85ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:104: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:105: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:106: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eligible_br_count:  121\n",
      "Result/Spring_DATAREST:\n",
      "\t ****  MAP:  0.44786744588808763 **** \n",
      "\t ****  MRR:  0.6631087552849046 **** \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "\t ****** Localizing Bugs for group: Spring , project: SECOAUTH ******\n",
      "Localizing Now ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b931aa3cf40a4623a5c534b18840316f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eligible_br_count:  66\n",
      "Result/Spring_SECOAUTH:\n",
      "\t ****  MAP:  0.4176536570043631 **** \n",
      "\t ****  MRR:  0.49445861053586343 **** \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "\t ****** Localizing Bugs for group: Spring , project: ROO ******\n",
      "Localizing Now ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca99dd06aed4ff5acfaf5d213debc87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eligible_br_count:  558\n",
      "Result/Spring_ROO:\n",
      "\t ****  MAP:  0.34986977956236903 **** \n",
      "\t ****  MRR:  0.44496014246082394 **** \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "\t ****** Localizing Bugs for group: Spring , project: DATAGRAPH ******\n",
      "Localizing Now ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a422edbb0944984ab2f9e803acb8773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eligible_br_count:  12\n",
      "Result/Spring_DATAGRAPH:\n",
      "\t ****  MAP:  0.16595826716596188 **** \n",
      "\t ****  MRR:  0.23623327187860063 **** \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "\t ****** Localizing Bugs for group: Spring , project: SHL ******\n",
      "Localizing Now ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615797c0388449afab5f0b4d8ef3c274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eligible_br_count:  10\n",
      "Result/Spring_SHL:\n",
      "\t ****  MAP:  0.33752621171495306 **** \n",
      "\t ****  MRR:  0.4061633999235698 **** \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "\t ****** Localizing Bugs for group: Spring , project: SOCIALLI ******\n",
      "Localizing Now ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0df1d160c1e4c1ebcef5d6c21901e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eligible_br_count:  4\n",
      "Result/Spring_SOCIALLI:\n",
      "\t ****  MAP:  0.3998484650270364 **** \n",
      "\t ****  MRR:  0.65625 **** \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "\t ****** Localizing Bugs for group: Spring , project: SGF ******\n",
      "Localizing Now ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0358937ce35a4a42a129ec04f9873fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eligible_br_count:  98\n",
      "Result/Spring_SGF:\n",
      "\t ****  MAP:  0.3821398990617936 **** \n",
      "\t ****  MRR:  0.6261971082388222 **** \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "\t ****** Localizing Bugs for group: Spring , project: SEC ******\n",
      "Localizing Now ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957d008e25df419d8abe37db4ed1fed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eligible_br_count:  362\n",
      "Result/Spring_SEC:\n",
      "\t ****  MAP:  0.47845770799489235 **** \n",
      "\t ****  MRR:  0.5996794446639655 **** \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "\t ****** Localizing Bugs for group: Spring , project: LDAP ******\n",
      "Localizing Now ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8683d82fcc4a5e98c49c72cceb1c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eligible_br_count:  52\n",
      "Result/Spring_LDAP:\n",
      "\t ****  MAP:  0.3801187241561234 **** \n",
      "\t ****  MRR:  0.4778642203698764 **** \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "\t ****** Localizing Bugs for group: Spring , project: DATAREDIS ******\n",
      "Localizing Now ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6683727ef6ec48499dac116fc0e704a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eligible_br_count:  49\n",
      "Result/Spring_DATAREDIS:\n",
      "\t ****  MAP:  0.5313276072268275 **** \n",
      "\t ****  MRR:  0.7612657184085757 **** \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "\t ****** Localizing Bugs for group: Spring , project: AMQP ******\n",
      "Localizing Now ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957f4b9e354849bead0907ad5ae81c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eligible_br_count:  97\n",
      "Result/Spring_AMQP:\n",
      "\t ****  MAP:  0.3774103471634547 **** \n",
      "\t ****  MRR:  0.5389638733299548 **** \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "\t ****** Localizing Bugs for group: Spring , project: SOCIAL ******\n",
      "Localizing Now ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c620969e5a546768a4dcf592db08474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eligible_br_count:  13\n",
      "Result/Spring_SOCIAL:\n",
      "\t ****  MAP:  0.5998907006060389 **** \n",
      "\t ****  MRR:  0.6186384765332134 **** \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "\t ****** Localizing Bugs for group: Spring , project: SPR ******\n",
      "Localizing Now ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2841f82919a543b4bad895f1d09ee062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eligible_br_count:  123\n",
      "Result/Spring_SPR:\n",
      "\t ****  MAP:  0.2733090670006579 **** \n",
      "\t ****  MRR:  0.361699803254431 **** \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "\t ****** Localizing Bugs for group: Spring , project: SOCIALTW ******\n",
      "Localizing Now ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9107d74dbffb4d989506efe24bdfc81c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eligible_br_count:  8\n",
      "Result/Spring_SOCIALTW:\n",
      "\t ****  MAP:  0.80625 **** \n",
      "\t ****  MRR:  0.8375 **** \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "\t ****** Localizing Bugs for group: Spring , project: DATACMNS ******\n",
      "Localizing Now ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d48b8486716450395b931224b7315b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eligible_br_count:  152\n",
      "Result/Spring_DATACMNS:\n",
      "\t ****  MAP:  0.5074509743640699 **** \n",
      "\t ****  MRR:  0.6725420568575324 **** \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "\t ****** Localizing Bugs for group: Spring , project: BATCHADM ******\n",
      "Localizing Now ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7e367b24421452c8147d85503d0f4d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eligible_br_count:  20\n",
      "Result/Spring_BATCHADM:\n",
      "\t ****  MAP:  0.46917767764120644 **** \n",
      "\t ****  MRR:  0.5845360195360195 **** \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "\t ****** Localizing Bugs for group: Spring , project: MOBILE ******\n",
      "Localizing Now ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4330f1947b09429394de7272a269a77d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eligible_br_count:  11\n",
      "Result/Spring_MOBILE:\n",
      "\t ****  MAP:  0.6433744811854553 **** \n",
      "\t ****  MRR:  0.8363636363636363 **** \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "\t ****** Localizing Bugs for group: Spring , project: BATCH ******\n",
      "Localizing Now ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7692bf169b5d41d892f3e776c305b42c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eligible_br_count:  354\n",
      "Result/Spring_BATCH:\n",
      "\t ****  MAP:  0.4043184845027857 **** \n",
      "\t ****  MRR:  0.5903866465896869 **** \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "\t ****** Localizing Bugs for group: Spring , project: SHDP ******\n",
      "Localizing Now ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e681abb3541543a49c8d6803c0fd2997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eligible_br_count:  45\n",
      "Result/Spring_SHDP:\n",
      "\t ****  MAP:  0.4300863363259259 **** \n",
      "\t ****  MRR:  0.5800120979341532 **** \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "\t ****** Localizing Bugs for group: Spring , project: ANDROID ******\n",
      "Localizing Now ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c2fc977d045460ea99fc721c086161c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eligible_br_count:  9\n",
      "Result/Spring_ANDROID:\n",
      "\t ****  MAP:  0.3220963116423541 **** \n",
      "\t ****  MRR:  0.6462962962962963 **** \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "\t ****** Localizing Bugs for group: Spring , project: SOCIALFB ******\n",
      "Localizing Now ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d941a43109d49d1bb1c6f0cbe68b9bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eligible_br_count:  15\n",
      "Result/Spring_SOCIALFB:\n",
      "\t ****  MAP:  0.505007651857174 **** \n",
      "\t ****  MRR:  0.5861375661375661 **** \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "\t ****** Localizing Bugs for group: Spring , project: DATAMONGO ******\n",
      "Localizing Now ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e0cc4102bf0463ba5297795a3f41452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eligible_br_count:  264\n",
      "Result/Spring_DATAMONGO:\n",
      "\t ****  MAP:  0.3519085164109085 **** \n",
      "\t ****  MRR:  0.5070100211174262 **** \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "\t ****** Localizing Bugs for group: Spring , project: SWF ******\n",
      "Localizing Now ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57949e34e8224a24a8d4ab866d136106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eligible_br_count:  105\n",
      "Result/Spring_SWF:\n",
      "\t ****  MAP:  0.4398811329192849 **** \n",
      "\t ****  MRR:  0.5474363308248886 **** \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "\t ****** Localizing Bugs for group: Spring , project: SWS ******\n",
      "Localizing Now ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b56b595c63bf4ec481bdb78b4d86aa3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eligible_br_count:  159\n",
      "Result/Spring_SWS:\n",
      "\t ****  MAP:  0.42147183496132107 **** \n",
      "\t ****  MRR:  0.5346497747531151 **** \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "\t ****** Localizing Bugs for group: Spring , project: DATAJPA ******\n",
      "Localizing Now ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f962e6d673f4df2abefece102fcb132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eligible_br_count:  144\n",
      "Result/Spring_DATAJPA:\n",
      "\t ****  MAP:  0.47949330184682837 **** \n",
      "\t ****  MRR:  0.6862801022681223 **** \n",
      " ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def folder_structure(run_name):\n",
    "    result_path=os.path.join(os.getcwd(),\"Result\",run_name,strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
    "    if not os.path.exists(result_path):\n",
    "        os.makedirs(result_path)\n",
    "    return result_path\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "\n",
    "    run_name='8-GlobalWEBugLocator'\n",
    "    result_path=folder_structure(run_name)\n",
    "    BugLocalizer.dataFolder=os.path.join(os.getcwd(),'Data')\n",
    "    if BugLocalizer.all_projects_bugreports.empty or BugLocalizer.all_projects_source_codes.empty:\n",
    "        BugLocalizer.loadEverything()\n",
    "    \n",
    "    all_projects=set(BugLocalizer.all_projects_bugreports.project)\n",
    "\n",
    "    for project in all_projects:\n",
    "        core=BugLocalizer(project=project,result_path=result_path)\n",
    "        core.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<center><h1>Result</h1></center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "method='8-GlobalWEBugLocator'\n",
    "runNumber=\"run\"\n",
    "all_results_csv=[os.path.join(os.getcwd(),\"Result\",method,runNumber,folder) \n",
    "                 for folder in listdir(os.path.join(os.getcwd(),\"Result\",method,runNumber)) if '.csv' in folder]\n",
    "results_df=pd.DataFrame([])\n",
    "for result_csv in all_results_csv:\n",
    "    res=pd.read_csv(result_csv,index_col=[0],header=0)\n",
    "    results_df=results_df.append(res)\n",
    "\n",
    "project_size_df=pd.read_csv('project_size.csv',index_col=[0],header=0)\n",
    "results_df\n",
    "results_df=pd.merge(results_df, project_size_df,\n",
    "                                      left_index=True,\n",
    "                                      right_index=True)\n",
    "results_df=results_df.reset_index()\n",
    "results_df=results_df.set_index(' #ofBugReports')\n",
    "\n",
    "results_df.to_csv(os.path.join(os.getcwd(),\"Result\",method,'result.csv'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
