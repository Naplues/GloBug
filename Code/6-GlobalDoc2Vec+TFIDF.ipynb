{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>General Global Doc2Vec + TFIDF</h1></center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this method, we first create a general global Doc2Vec using all bug reports and all source codes of all projects. Later we perform the localization using the trained model and the TFIDF similarity score of bug reports to source codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import operator\n",
    "import traceback\n",
    "import logging\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim import similarities\n",
    "from gensim import models\n",
    "\n",
    "import math \n",
    "import xml.etree.ElementTree as ET\n",
    "import multiprocessing\n",
    "from tqdm import tqdm_notebook\n",
    "from time import gmtime, strftime\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Evaluators</h1></center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_helper(ranked_files,fixes):\n",
    "    \"\"\"\n",
    "    @Receives: list of ranked files(which is predicted by algorithm) and the ground truth(fixes)\n",
    "    @Process: This is a function aimed to help evaluate, and calculates the AP and first_pos \n",
    "    @Returns: A dictionary containing the AP(average precision) and first_pos (first retrieved fix file)\n",
    "    \"\"\"\n",
    "    found=0\n",
    "    first_pos=-1\n",
    "    average_precision=0\n",
    "    for i,predictionFix in enumerate(ranked_files):\n",
    "        for actualFix in fixes:\n",
    "            if actualFix.split('.')[-2] == predictionFix:\n",
    "                if first_pos==-1:\n",
    "                    first_pos=i+1\n",
    "                found+=1\n",
    "                average_precision+=found/(i+1)        \n",
    "\n",
    "    AP=average_precision/found if found>0 else 0\n",
    "    return {\"AP\":AP,\"first_pos\":first_pos}\n",
    "\n",
    "\n",
    "def evaluate(all_bugs_df,source_codes_df):\n",
    "    \"\"\"\n",
    "    @Receives: The main dataframes \n",
    "    @Process: Evaluates the predicted files for each bugreport in all_bugs_df\n",
    "    @Returns: MAP and MRR calculated from eligible bugreports(the ones with\n",
    "    at least one fix file in this version of code) in the dataframe and number of eligible bug reports.\n",
    "    \"\"\"\n",
    "    all_results=[]\n",
    "    top_founds=[]\n",
    "    average_precisions=[]\n",
    "    for i,br in all_bugs_df.iterrows():\n",
    "        if not source_codes_df.loc[source_codes_df.filename.apply(lambda filename: any(fix in filename for fix in br['fix']))].empty:\n",
    "            predicted_files=br['total_score'].keys()\n",
    "            result=evaluate_helper(predicted_files,br['fix'])\n",
    "            top_founds.append(result['first_pos'])\n",
    "            average_precisions.append(result['AP'])\n",
    "            all_results.append(result)\n",
    "        else:\n",
    "            top_founds.append(-1)\n",
    "            average_precisions.append(0.0)\n",
    "    all_bugs_df[\"top_found\"]=top_founds\n",
    "    all_bugs_df[\"average_precision\"]=average_precisions\n",
    "    \n",
    "    #Calculating the MAP and MRR\n",
    "    MAP,MRR=(0,0)\n",
    "    if len(all_results)>0:\n",
    "        for result in all_results:\n",
    "            MAP+=result['AP']\n",
    "            MRR+=1/result['first_pos'] if result['first_pos']>0 else 0\n",
    "        MAP/=len(all_results)\n",
    "        MRR/=len(all_results)\n",
    "        print(\"eligible_br_count: \",len(all_results))\n",
    "    return (MAP,MRR,len(all_results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>TFIDF</h1></center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNormValue(x,maximum,minimum):\n",
    "    return 6*((x - minimum)/(maximum - minimum))\n",
    "\n",
    "def getLenScore(length):\n",
    "    return (math.exp(length) / (1 + math.exp(length)))\n",
    "\n",
    "def calulateLengthScore(source_codes_df):\n",
    "    \"\"\"\n",
    "    Receives: a list of sizes of codes and the index\n",
    "    Process: calculate a boost score for the specified index based on length of that code\n",
    "    Returns: length boosting score \n",
    "    \"\"\"\n",
    "    average_size=source_codes_df['size'].mean()\n",
    "    standard_deviation=source_codes_df['size'].std() \n",
    "    low=average_size-3*standard_deviation\n",
    "    high= average_size+3*standard_deviation\n",
    "    minimum=int(low) if low>0 else 0\n",
    "        \n",
    "    len_scores=[]\n",
    "    for i,eachLen in source_codes_df['size'].items():\n",
    "        score=0\n",
    "        nor=getNormValue(eachLen,high,minimum)\n",
    "        if eachLen!=0:\n",
    "            if eachLen>=low and eachLen<=high:\n",
    "                score=getLenScore(nor)\n",
    "            elif eachLen<low:\n",
    "                score=0.5\n",
    "            elif eachLen>high:\n",
    "                score = 1.0\n",
    "        len_scores.append(score)\n",
    "    source_codes_df['lengthScore']=len_scores\n",
    "\n",
    "    return source_codes_df\n",
    "    \n",
    "def inverse_doc_freq(idf,D):\n",
    "    return math.log(D/idf)\n",
    "\n",
    "def term_freq(tf_list):\n",
    "    return [(math.log(tf+1)) for tf in tf_list]\n",
    "\n",
    "def np_normalizer(arr):\n",
    "    \"\"\"\n",
    "    @Receives: a list of numbers\n",
    "    @Process: normalizes all the values and map them to range of [0,1]\n",
    "    @Returns: list of normalized numbers\n",
    "    \"\"\"\n",
    "    if len(arr)>0:\n",
    "        maximum=np.amax(arr)\n",
    "        minimum=np.amin(arr)\n",
    "        if maximum!=minimum:\n",
    "            return (arr-minimum)/(maximum-minimum)\n",
    "    return arr\n",
    "\n",
    "def normalizer(Dict):\n",
    "    \"\"\"\n",
    "    @Receives: a list of numbers\n",
    "    @Process: normalizes all the values and map them to range of [0,1]\n",
    "    @Returns: list of normalized numbers\n",
    "    \"\"\"\n",
    "    if len(Dict)>0:\n",
    "        maximum=max(Dict.items(), key=operator.itemgetter(1))[1]\n",
    "        minimum=min(Dict.items(), key=operator.itemgetter(1))[1]\n",
    "        for key,value in Dict.items():\n",
    "            if maximum!=minimum:\n",
    "                Dict[key]=(value-minimum)/(maximum-minimum)\n",
    "            else:\n",
    "                Dict[key]=1.0\n",
    "    return Dict\n",
    "    \n",
    "\n",
    "def TFIDF_transform(all_bugs_df,source_codes_df):\n",
    "\n",
    "    dictionary = gensim.corpora.Dictionary(list(source_codes_df['code']))\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in list(source_codes_df['code'])]\n",
    "    tfidf_weights = models.TfidfModel(corpus,wlocal=term_freq,wglobal=inverse_doc_freq,normalize=False)\n",
    "    source_codes_df['tfidf_vector']=tfidf_weights[corpus]\n",
    "    all_bugs_df['tfidf_vector']=all_bugs_df.text.apply(lambda x: tfidf_weights[dictionary.doc2bow(x)])\n",
    "    return (all_bugs_df,source_codes_df,len(dictionary))\n",
    "\n",
    "def cos_matrix_multiplication(matrix, vector):\n",
    "    \"\"\"\n",
    "    Calculating pairwise cosine distance using matrix vector multiplication.\n",
    "    \"\"\"\n",
    "    dotted = matrix.dot(vector)\n",
    "    matrix_norms = np.linalg.norm(matrix, axis=1)\n",
    "    vector_norm = np.linalg.norm(vector)\n",
    "    matrix_vector_norms = np.multiply(matrix_norms, vector_norm)\n",
    "    neighbors = np.divide(dotted, matrix_vector_norms)\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> Genral Global Doc2Vec Model </h1></center> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_Doc2Vec_models(vec_size,alpha,window_size,all_bugs_df,source_codes_df):\n",
    "    \"\"\"\n",
    "    Process: 1- Loads all the bug reports from all the group/projects in Data directory\n",
    "             2- Makes a Doc2Vec model and trains it based on all the bugreports\n",
    "    Returns: Trained model\n",
    "    \"\"\"\n",
    "    print(\"\\n\\t Now building the Combined Doc2Vec model ... \")\n",
    "    dmm_model_path=os.path.join(os.getcwd(),'Models','combined_doc2vec_model_dmm')\n",
    "    dbow_model_path=os.path.join(os.getcwd(),'Models','combined_doc2vec_model_dbow')\n",
    "    fname_dmm = get_tmpfile(dmm_model_path)\n",
    "    fname_dbow = get_tmpfile(dbow_model_path)\n",
    "    if os.path.isfile(dmm_model_path) and os.path.isfile(dbow_model_path):\n",
    "        revectorize=False\n",
    "        model_dmm = Doc2Vec.load(fname_dmm)\n",
    "        model_dbow = Doc2Vec.load(fname_dbow)\n",
    "        print(\"*** Combined Doc2Vec Model is Loaded. ***\")            \n",
    "    else:\n",
    "        revectorize=True\n",
    "        documents = [TaggedDocument(all_bugs_df.iloc[i].text, [i]) for i in range(len(all_bugs_df))]\n",
    "        documents = documents + [TaggedDocument(source_codes_df.iloc[i].code, [len(all_bugs_df)+i]) for i in range(len(source_codes_df))]\n",
    "\n",
    "        model_dmm = Doc2Vec(vector_size=vec_size, window=window_size, min_count=2,\n",
    "                        workers=multiprocessing.cpu_count(),\n",
    "                        alpha=alpha, min_alpha=alpha/2,dm=1)\n",
    "        model_dmm.build_vocab(documents)\n",
    "        model_dmm.train(documents,total_examples=model_dmm.corpus_count,epochs=20)\n",
    "        model_dmm.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "        model_dmm.save(fname_dmm)\n",
    "        \n",
    "        model_dbow = Doc2Vec(dm=0, vector_size=vec_size, negative=5,\n",
    "                             hs=0,min_count=2, sample = 0, workers=multiprocessing.cpu_count(),\n",
    "                             alpha=alpha, min_alpha=alpha/3)\n",
    "        model_dbow.build_vocab(documents)\n",
    "        model_dbow.train(documents,total_examples=model_dbow.corpus_count,epochs=20)\n",
    "        model_dbow.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "        model_dbow.save(fname_dbow)\n",
    "        print(\"*** Combined Doc2Vec Model is Trained. ***\")\n",
    "    concatinated_model = ConcatenatedDoc2Vec([model_dbow, model_dmm])\n",
    "    print(\">> Size of Vocabulary is: {}\".format(len(model_dmm.wv.vocab)))\n",
    "    print(\">> Number of whole Documents: {}\".format(model_dmm.corpus_count))\n",
    "    \n",
    "    return (concatinated_model,revectorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize(sourceCodeScores,bugReportScores):\n",
    "    sourceCodeScores=normalizer(sourceCodeScores)\n",
    "    bugReportScores=normalizer(bugReportScores)\n",
    "    for file in bugReportScores.keys():\n",
    "        if file in sourceCodeScores.keys():\n",
    "            sourceCodeScores[file]=sourceCodeScores[file]*0.8+bugReportScores[file]*0.2\n",
    "    return sourceCodeScores\n",
    "\n",
    "def combine(scoring_one, scoring_two):\n",
    "    scoring_one=np_normalizer(scoring_one)  \n",
    "    scoring_two=np_normalizer(scoring_two)\n",
    "    result=scoring_one+scoring_two\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<center><h1>Main BugLocalization class</h1></center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BugLocalizer:\n",
    "\n",
    "    combined_Doc2vec=None\n",
    "    TFIDF_transformed=False\n",
    "    dictionary_length=0\n",
    "    all_projects_source_codes=pd.DataFrame([])\n",
    "    all_projects_bugreports=pd.DataFrame([])\n",
    "    dataFolder=\"\"\n",
    "    vectorize=True\n",
    "    \n",
    "    def __init__(self,project,result_path):\n",
    "        self.project=project\n",
    "        self.resultPath=result_path\n",
    "\n",
    "\n",
    "            \n",
    "    def execute(self):\n",
    "        print(\"\\t ****** Localizing Bugs for project: {} ******\".format(self.project))\n",
    "\n",
    "        revectorize=False\n",
    "        if BugLocalizer.combined_Doc2vec==None:\n",
    "            (BugLocalizer.combined_Doc2vec,revectorize)=build_Doc2Vec_models(vec_size=100,alpha=0.045,window_size=5,\n",
    "                                               all_bugs_df=BugLocalizer.all_projects_bugreports,\n",
    "                                               source_codes_df=BugLocalizer.all_projects_source_codes)\n",
    "        if not BugLocalizer.TFIDF_transformed:\n",
    "            (self.all_projects_bugreports,BugLocalizer.all_projects_source_codes,BugLocalizer.dictionary_length)=TFIDF_transform(all_bugs_df=BugLocalizer.all_projects_bugreports,\n",
    "                                                                                                     source_codes_df=BugLocalizer.all_projects_source_codes)                                       \n",
    "            BugLocalizer.TFIDF_transformed=True\n",
    "            \n",
    "        if BugLocalizer.vectorize:\n",
    "            print('\\n\\t Vectorizing Now ...')\n",
    "            self.vectorizeBugreports()\n",
    "            self.vectorizeSourceCodes()\n",
    "            bugReportFile=os.path.join(BugLocalizer.dataFolder,'allBugReports.pickle')\n",
    "            sourceCodeFile=os.path.join(BugLocalizer.dataFolder,'allSourceCodes.pickle')\n",
    "            BugLocalizer.all_projects_bugreports.to_pickle(bugReportFile)\n",
    "            BugLocalizer.all_projects_source_codes.to_pickle(sourceCodeFile)\n",
    "            BugLocalizer.vectorize=False\n",
    "            \n",
    "        self.loadBugCurpus()\n",
    "        self.loadSourceFiles()\n",
    "        self.localize()\n",
    "        self.evaluate()\n",
    "        self.to_csv()\n",
    "        self.write_result()\n",
    "        \n",
    "    def loadEverything():\n",
    "        if BugLocalizer.all_projects_bugreports.empty:\n",
    "            bugReportFile=os.path.join(BugLocalizer.dataFolder,'allBugReports.pickle')\n",
    "            if not os.path.isfile(bugReportFile):\n",
    "                print(\"The bug reports file (allBugReports.pickle) does not exist. please run the step0 first\")\n",
    "            else: \n",
    "                BugLocalizer.all_projects_bugreports=pd.read_pickle(bugReportFile)\n",
    "                print(\"*** All Bug Reports are Loaded. ***\")\n",
    "\n",
    "        if BugLocalizer.all_projects_source_codes.empty:\n",
    "            sourceCodeFile=os.path.join(BugLocalizer.dataFolder,'allSourceCodes.pickle')\n",
    "            if not os.path.isfile(sourceCodeFile):\n",
    "                print(\"The source codes file (allSourceCodes.pickle) does not exist. please run the step0 first\")\n",
    "            else:\n",
    "                BugLocalizer.all_projects_source_codes=pd.read_pickle(sourceCodeFile)\n",
    "                print(\"*** All Source Codes are Loaded. ***\")\n",
    "    \n",
    "    \n",
    "    def loadBugCurpus(self):\n",
    "        self.all_bugs_df=BugLocalizer.all_projects_bugreports.loc[BugLocalizer.all_projects_bugreports['project']==self.project,:]\n",
    "        self.group=self.all_bugs_df[\"group\"][0]\n",
    "        \n",
    "    def loadSourceFiles(self):\n",
    "        self.source_codes_df=BugLocalizer.all_projects_source_codes.loc[BugLocalizer.all_projects_source_codes['project']==self.project,:]\n",
    "    \n",
    "    def vectorizeBugreports(self):\n",
    "        BugLocalizer.all_projects_bugreports['doc2vec_vector']=np.array(BugLocalizer.all_projects_bugreports.text.apply(BugLocalizer.combined_Doc2vec.infer_vector))\n",
    "        \n",
    "    def vectorizeSourceCodes(self):\n",
    "        BugLocalizer.all_projects_source_codes['doc2vec_vector']=np.array(BugLocalizer.all_projects_source_codes.code.apply(BugLocalizer.combined_Doc2vec.infer_vector))\n",
    "     \n",
    "\n",
    "    def localize(self):\n",
    "        \n",
    "        print(\"Localizing Now ...\")\n",
    "        scores=[]\n",
    "        \n",
    "        self.source_codes_df=calulateLengthScore(self.source_codes_df)\n",
    "        \n",
    "        direct_tfidf_index = similarities.SparseMatrixSimilarity(list(self.source_codes_df.tfidf_vector),num_features=BugLocalizer.dictionary_length)\n",
    "        direct_WE_index=np.array(list(self.source_codes_df.doc2vec_vector))\n",
    "        \n",
    "        indirect_tfidf_index = similarities.SparseMatrixSimilarity(list(self.all_bugs_df.tfidf_vector),num_features=BugLocalizer.dictionary_length)\n",
    "        indirect_WE_index=np.array(list(self.all_bugs_df.doc2vec_vector))\n",
    "        \n",
    "        for i, br in tqdm_notebook(self.all_bugs_df.iterrows()):\n",
    "            \n",
    "            try:\n",
    "                direct_doc2vec_similarities=cos_matrix_multiplication(direct_WE_index, br.doc2vec_vector)\n",
    "                direct_tfidf_similarities=direct_tfidf_index[br.tfidf_vector]\n",
    "                direct_similarities=combine(direct_tfidf_similarities,direct_doc2vec_similarities)\n",
    "                sourceCodeScores={self.source_codes_df.iloc[j].filename.split('.')[-2]: (direct_similarities[j])*self.source_codes_df.iloc[j].lengthScore \n",
    "                                                  for j in range(len(self.source_codes_df))\n",
    "                                                  if len(self.source_codes_df.iloc[j].filename.split('.'))>1}\n",
    "              \n",
    "                \n",
    "                indirect_doc2vec_similarities=cos_matrix_multiplication(indirect_WE_index, br.doc2vec_vector)\n",
    "                indirect_tfidf_similarities=indirect_tfidf_index[br.tfidf_vector]\n",
    "                indirect_similarities=combine(indirect_tfidf_similarities,indirect_doc2vec_similarities)\n",
    "                bugReportScores=dict({})\n",
    "                for j,(idx,other_br) in enumerate(self.all_bugs_df.iterrows()):\n",
    "                    for fixFile in other_br.fix:\n",
    "                        if idx != i:\n",
    "                            if fixFile.split('.')[-2] in bugReportScores.keys():\n",
    "                                if indirect_similarities[j]>=bugReportScores[fixFile.split('.')[-2]]:\n",
    "                                    bugReportScores[fixFile.split('.')[-2]]=indirect_similarities[j]\n",
    "                            else:\n",
    "                                bugReportScores[fixFile.split('.')[-2]]=indirect_similarities[j]\n",
    "                                   \n",
    "                ranking=synthesize(sourceCodeScores,bugReportScores)\n",
    "                scores.append({file:score for file,score in sorted(ranking.items(),key=lambda tup: tup[1],reverse=True)})\n",
    "                \n",
    "            except Exception as e:\n",
    "                logging.error(traceback.format_exc())\n",
    "                scores.append({})             \n",
    "                \n",
    "        self.all_bugs_df['total_score']=scores\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.result=evaluate(self.all_bugs_df,self.source_codes_df)\n",
    "        print(\"Result/\"+self.group+\"_\"+self.project+\":\\n\\t\",'*'*4,\" MAP: \",self.result[0],'*'*4,'\\n\\t','*'*4,\" MRR: \",self.result[1],'*'*4,\"\\n\",\"-\"*100)\n",
    "\n",
    "    def to_csv(self):\n",
    "        BugReports_path=os.path.join(self.resultPath,'BugReports') \n",
    "        SourceFiles_path=os.path.join(self.resultPath,'SourceFiles')\n",
    "        if not os.path.exists(BugReports_path):\n",
    "            os.makedirs(BugReports_path)\n",
    "        if not os.path.exists(SourceFiles_path):\n",
    "            os.makedirs(SourceFiles_path)\n",
    "        result_Bug_file=os.path.join(BugReports_path,self.project+\"_BugReports.csv\")\n",
    "        result_source_file=os.path.join(SourceFiles_path,self.project+\"_SourceFiles.csv\")\n",
    "        self.all_bugs_df.to_csv(result_Bug_file)\n",
    "        if len(self.source_codes_df)<300:\n",
    "            self.source_codes_df.to_csv(result_source_file)\n",
    "        \n",
    "    def write_result(self):\n",
    "        group_result=open(os.path.join(self.resultPath,\"results_{}_{}.csv\".format(self.group,self.project)),'w')\n",
    "        group_result.write(group+\" , MAP , MRR , #ofBugReports\\n\")\n",
    "        group_result.write(project+','+str(self.result[0])+','+str(self.result[1])+','+str(self.result[2])+\"\\n\")\n",
    "        group_result.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "            \n",
    "def folder_structure(run_name):\n",
    "    result_path=os.path.join(os.getcwd(),\"Result\",run_name,strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
    "    if not os.path.exists(result_path):\n",
    "        os.makedirs(result_path)\n",
    "    return result_path\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "\n",
    "    run_name='3-GlobalDoc2Vec+tfidf'\n",
    "    result_path=folder_structure(run_name)\n",
    "    BugLocalizer.dataFolder=os.path.join(os.getcwd(),'Data')\n",
    "    BugLocalizer.loadEverything()\n",
    "    \n",
    "    all_projects=set(BugLocalizer.all_projects_bugreports.project)\n",
    "    for project in all_projects:\n",
    "        core=BugLocalizer(project=project,result_path=result_path)\n",
    "        core.execute()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<center><h1>Result</h1></center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method='3-GlobalDoc2Vec+tfidf'\n",
    "runNumber=\"run3\"\n",
    "all_results_csv=[os.path.join(os.getcwd(),\"Result\",method,runNumber,folder) \n",
    "                 for folder in listdir(os.path.join(os.getcwd(),\"Result\",method,runNumber)) if '.csv' in folder]\n",
    "results_df=pd.DataFrame([])\n",
    "for result_csv in all_results_csv:\n",
    "    res=pd.read_csv(result_csv,index_col=[0],header=0)\n",
    "    results_df=results_df.append(res)\n",
    "\n",
    "project_size_df=pd.read_csv('project_size.csv',index_col=[0],header=0)\n",
    "results_df\n",
    "results_df=pd.merge(results_df, project_size_df,\n",
    "                                      left_index=True,\n",
    "                                      right_index=True)\n",
    "results_df=results_df.reset_index()\n",
    "results_df=results_df.set_index(' #ofBugReports')\n",
    "\n",
    "results_df.to_csv(os.path.join(os.getcwd(),\"Result\",method,'result.csv'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
